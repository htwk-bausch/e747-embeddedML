{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ffe8d4c-5801-4511-97ea-29750396036b",
   "metadata": {},
   "source": [
    "# Gestenerkennung (Punch/Flex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef1737-9064-4315-ac2e-4924a2fc0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "!python --version\n",
    "print(\"NumPy: \" + np.__version__)\n",
    "print(\"Keras: \" + tf.keras.__version__)\n",
    "print(\"TensorFlow: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490ddce2",
   "metadata": {},
   "source": [
    "# Teil 1: Modellerstellung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d83ba60-5057-4cbd-a75f-98944b744d45",
   "metadata": {},
   "source": [
    "### Datensatz importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a853597-6e8d-4556-818f-3aedb2ed182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten importieren\n",
    "\n",
    "#df = pd.read_csv(\"../data/punch.csv\")\n",
    "df = pd.read_csv(\"../data/flex.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7407f-84bd-439d-8dd6-b30e4c455291",
   "metadata": {},
   "source": [
    "### Daten anzeigen/visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d944b-9ff0-4cfb-a89e-d94d1cfbdcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "#df.shape\n",
    "#df.min()\n",
    "#df.max()\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a55bd-b5f2-4473-8192-dc5e09933cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot der Beschleuniger-Daten\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.plot(df['aX'], 'g', label='x', linestyle='solid')\n",
    "plt.plot(df['aY'], 'b', label='y', linestyle='solid')\n",
    "plt.plot(df['aZ'], 'r', label='z', linestyle='solid')\n",
    "\n",
    "for i in range(9):\n",
    "  plt.vlines((i+1)*104, -4000, 4000, linestyle=\"dashed\", color='gray')\n",
    "\n",
    "plt.title(\"Beschleunigung\");\n",
    "plt.xlabel(\"Sample\");\n",
    "plt.ylabel(\"Beschleunigung (mG)\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e5ba40-62a1-44af-b409-6ac0b2f4274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot der Gyroskop-Daten\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.plot(df['gX'], 'g', label='x', linestyle='solid')\n",
    "plt.plot(df['gY'], 'b', label='y', linestyle='solid')\n",
    "plt.plot(df['gZ'], 'r', label='z', linestyle='solid')\n",
    "plt.title(\"Gyroskop\")\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.ylabel(\"Gyroskop (Grad/Sek)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72de3d00-7c15-4b43-a24d-f0ff466c9320",
   "metadata": {},
   "source": [
    "## Trainingsdaten vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d3050-4b96-4bc4-b0f8-4bebbb326e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zufallszahlengenerator fixieren (für reproduzierbare Ergebnisse)\n",
    "SEED = 1337\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "GESTURES = [\n",
    "    \"punch\",\n",
    "    \"flex\",\n",
    "]\n",
    "\n",
    "SAMPLES_PER_GESTURE = 104         # muss mit Wert in IMU_Capture (Arduino) übereinstimmen\n",
    "\n",
    "NUM_GESTURES = len(GESTURES)\n",
    "\n",
    "# One-Hot-Kodierte Matrix für Labels\n",
    "ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "# lese jede einzelne CSV-Datei ein und erzeuge die Trainingsdaten und Label\n",
    "# Serialisieren der Daten (6 Sensorkanäle á SAMPLES_PER_GESTURE)\n",
    "# Normalisierung der Daten\n",
    "for gesture_index in range(NUM_GESTURES):\n",
    "    \n",
    "  gesture = GESTURES[gesture_index]\n",
    "  print(f\"Verarbeite Index %d für Geste '%s'.\" % (gesture_index, gesture), end=\" \")\n",
    "  \n",
    "  output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
    "  \n",
    "  # Einlesen der CSV-Daten\n",
    "  df = pd.read_csv(\"../data/\" + gesture + \".csv\")\n",
    "  \n",
    "  # Berechnung der Anzahl der Aufnahmen pro Geste und Datei\n",
    "  # Anzahl aller Samples/Samples pro Geste\n",
    "  num_recordings = int(df.shape[0] / SAMPLES_PER_GESTURE)\n",
    "  \n",
    "  print(\"Im Datensatz wurden %d Aufzeichnungen für die Geste '%s' gefunden.\" % (num_recordings, gesture))\n",
    "  \n",
    "  # Daten normalisieren und serialisieren\n",
    "  for i in range(num_recordings):\n",
    "    tensor = []\n",
    "    for j in range(SAMPLES_PER_GESTURE):\n",
    "      index = i * SAMPLES_PER_GESTURE + j\n",
    "      # Normalisierung der Daten (0...1)\n",
    "      # - Beschleunigung: -4000 to +4000\n",
    "      # - Gyroskop: -2000 to +2000\n",
    "      tensor += [\n",
    "          (df['aX'][index] + 4000) / 8000,\n",
    "          (df['aY'][index] + 4000) / 8000,\n",
    "          (df['aZ'][index] + 4000) / 8000,\n",
    "          (df['gX'][index] + 8000) / 16000,\n",
    "          (df['gY'][index] + 8000) / 16000,\n",
    "          (df['gZ'][index] + 8000) / 16000\n",
    "      ]\n",
    "\n",
    "    inputs.append(tensor)\n",
    "    outputs.append(output)\n",
    "\n",
    "# Python-Listen in ein NumPy-Array konvertieren\n",
    "inputs  = np.array(inputs)\n",
    "outputs = np.array(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b06c21c-e17e-4e66-8bbe-73a02514732f",
   "metadata": {},
   "source": [
    "### Daten randomisieren\n",
    "\n",
    "Daten werden nun per Zufall gemischt: 60% Trainingsdaten, 20% Validierungsdaten und 20% Testdaten\n",
    "\n",
    "- Trainingsdaten: für das Training des Modells\n",
    "- Validierungsdaten: Berechnung der Performance während des Trainings\n",
    "- Testdaten: Test des Modells nach dem Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba64727-5c0c-4879-bcef-c59d4998aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = len(inputs)\n",
    "randomize = np.arange(num_inputs)\n",
    "np.random.shuffle(randomize)\n",
    "\n",
    "inputs = inputs[randomize]\n",
    "outputs = outputs[randomize]\n",
    "\n",
    "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
    "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
    "\n",
    "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb422c97-d7b6-4838-89fc-d5fd7aafc817",
   "metadata": {},
   "source": [
    "## Entwurf des neuronalen Netzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758658d-fbc0-45ea-a446-c6188e31c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Input(shape=[624,]))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(15, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192efc67-7b93-4695-9041-85f2e0b42228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kompilierung\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Zusammenfassung\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7200ec-6824-4119-afc1-7bb2d864b88d",
   "metadata": {},
   "source": [
    "## Training des neuronalen Netzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffde8e2-d797-43b0-a8c1-4e55c910ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(inputs_train, outputs_train, epochs=100, batch_size=1, verbose=1, validation_data=(inputs_validate, outputs_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce22c4a-f8f0-4720-9229-c535a20e2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsverlauf grafisch darstellen\n",
    "\n",
    "epochs = range(1, len(history.history['val_loss']) + 1)\n",
    "\n",
    "plt.figure(figsize=(8,7))\n",
    "plt.plot(epochs, history.history['val_loss'])\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Fehler')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf71a66-aae5-4000-9b02-cfe551ad6bc0",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa7ae39-786e-4d08-a601-0f2dde171fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(inputs_test)\n",
    "\n",
    "print(\"Vorhersage =\\n\", np.round(predictions, decimals=3))\n",
    "print(\"Label =\\n\", outputs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfda37a-1101-4a11-a7a6-37fc78ccfdee",
   "metadata": {},
   "source": [
    "# Teil 2: Portierung auf Mikrocontroller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3df590-540c-4758-8e4c-6dee8bdadef0",
   "metadata": {},
   "source": [
    "### Konvertierung in ein TensorFlow lite-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebfd318-a532-4610-a964-9912b0bc03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimazations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Modell speichern\n",
    "# Keras-Modell speichern\n",
    "open('gesture_model.tflite', 'wb').write(tflite_model);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embeddedml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
