{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c45fd8f",
   "metadata": {},
   "source": [
    "# Predictive Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003992a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97e13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version\n",
    "print(\"NumPy: \" + np.__version__)\n",
    "print(\"Keras: \" + tf.keras.__version__)\n",
    "print(\"TensorFlow: \" + tf.__version__)\n",
    "print(\"sklearn: \" + sklearn.__version__)\n",
    "\n",
    "# Hardwareunterstützung?\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859e081",
   "metadata": {},
   "source": [
    "## Datensätze importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15642935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1: Manuelle Auswahl der Daten\n",
    "\n",
    "#df = pd.read_csv('../data/fan_idle.csv')\n",
    "\n",
    "df = pd.read_csv('../data/fan_normal_speed1.csv')\n",
    "#df = pd.read_csv('../data/fan_normal_speed2.csv')\n",
    "#df = pd.read_csv('../data/fan_normal_speed3.csv')\n",
    "\n",
    "#df = pd.read_csv('../data/fan_unbalanced_speed1.csv')\n",
    "#df = pd.read_csv('../data/fan_unbalanced_speed2.csv')\n",
    "#df = pd.read_csv('../data/fan_unbalanced_speed3.csv')\n",
    "\n",
    "#df = pd.read_csv('../data/fan_clogged_speed1.csv'\n",
    "#df = pd.read_csv('../data/fan_clogged_speed2.csv')\n",
    "#df = pd.read_csv('../data/fan_clogged_speed3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2: Verarbeitung aller Dateien im Verzeichnis 'data_selected'\n",
    "\n",
    "samplingFreq = 1620    # Abtastfrequenz in Hertz\n",
    "bufferSize   = 256     # Blockgröße eines Buffers\n",
    "dataSets     = 40      # Anzahl an Datensätzen pro Klasse\n",
    "\n",
    "fan_data_tmp  = np.empty([0, bufferSize])       # leere Matrix für Daten\n",
    "fan_labels_tmp = np.array([])                    # leerer Vektor für Klassen\n",
    "\n",
    "path  = '../data_selected/'\n",
    "files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "files.sort()\n",
    "\n",
    "# Dateien einlesen und Daten/Klassen ablegen\n",
    "for labelID, file in enumerate(files):\n",
    "\n",
    "  print(\"Class %d (%s): \" % (labelID, file), end=\"\")\n",
    "  df = pd.read_csv(path + file)\n",
    "  print(\"found %d samples\" % len(df))\n",
    "\n",
    "  data = np.array(df['aX'])                    # nur Daten der X-Achse extrahieren\n",
    "  data = data-data.mean()                      # Gleichanteile entfernen\n",
    "  data = data.reshape(dataSets, bufferSize)    # Vektor in Matrix transformieren\n",
    "\n",
    "  # Daten und Klasse hinzufügen\n",
    "  fan_data_tmp  = np.concatenate([fan_data_tmp, data], axis=0)\n",
    "  fan_labels_tmp = np.concatenate([fan_labels_tmp, np.full((dataSets), labelID)])\n",
    "\n",
    "  numClasses = labelID+1\n",
    "\n",
    "fan_labels_tmp = tf.keras.utils.to_categorical(fan_labels_tmp, numClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc5eb39",
   "metadata": {},
   "source": [
    "### Daten mischen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae878d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_idx = np.arange(len(fan_data_tmp))\n",
    "random.shuffle(new_idx)\n",
    "\n",
    "fan_data   = np.empty([len(fan_data_tmp), bufferSize])\n",
    "fan_labels = np.empty([len(fan_labels_tmp), labelID+1])\n",
    "\n",
    "for i in np.arange(len(fan_data)):\n",
    "  fan_data[new_idx[i]]  = fan_data_tmp[i]\n",
    "  fan_labels[new_idx[i]] = fan_labels_tmp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501fabed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(id):\n",
    "\n",
    "  t = np.arange(bufferSize)/samplingFreq\n",
    "  \n",
    "  plt.figure(figsize=(12,4))\n",
    "  plt.plot(t, fan_data[id])\n",
    "\n",
    "  plt.xlabel('Zeit (Sekunden)')\n",
    "  plt.ylabel('aX ($m/s^2$)')\n",
    "  plt.title('Class %d' % fan_labels[id].argmax())\n",
    "  plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fcc97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28291073",
   "metadata": {},
   "source": [
    "## FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a9c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = bufferSize\n",
    "\n",
    "fan_data_fft  = np.empty([fan_data.shape[0], fan_data.shape[1]//2])       # leere Matrix für Daten (FFT)\n",
    "\n",
    "# Berechne FFT und Normalisiere Werte\n",
    "for i in np.arange(len(fan_data)):\n",
    "\n",
    "  Y     = scipy.fft.fft(fan_data[i])\n",
    "  Y_fft = 2.0/N * np.abs(Y[0:N//2])\n",
    "  peak_ = np.max(Y_fft)\n",
    "  fan_data_fft[i] = Y_fft/peak_      # normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFFT(data, label):\n",
    "\n",
    "  N = 2*len(data)\n",
    "  freq_ = scipy.fft.fftfreq(N, 1/samplingFreq)[:N//2]\n",
    "\n",
    "  peaks, _ = scipy.signal.find_peaks(data, height=0.01, distance=100)\n",
    "\n",
    "  plt.figure(figsize=(12,4))\n",
    "  plt.plot(freq_, data)\n",
    "  plt.plot(freq_[peaks], data[peaks], \"x\")\n",
    "  plt.title(\"Class: %d\" % label.argmax())\n",
    "  plt.xlabel('Frequenz (Hz)')\n",
    "  plt.ylabel('Betrag (norm)')\n",
    "  plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ba10a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "plotFFT(fan_data_fft[index], fan_labels[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb252ab",
   "metadata": {},
   "source": [
    "### Daten splitten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f195d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = len(fan_data)\n",
    "\n",
    "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
    "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
    "\n",
    "fan_data_train, fan_data_test, fan_data_val       = np.split(fan_data_fft, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "fan_labels_train, fan_labels_test, fan_labels_val = np.split(fan_labels, [TRAIN_SPLIT, TEST_SPLIT])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd0106",
   "metadata": {},
   "source": [
    "## Entwurf und Training des neuronalen Netzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f02e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=[bufferSize//2,]))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(numClasses, activation='softmax'))\n",
    "\n",
    "# Zusammenfassung\n",
    "#model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "history = model.fit(fan_data_train, fan_labels_train, batch_size=10, epochs=50, verbose=1, validation_data=(fan_data_val, fan_labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainingsverlauf grafisch darstellen\n",
    "epochs = range(1, len(history.history['val_loss']) + 1)\n",
    "\n",
    "plt.figure(figsize=(8,7))\n",
    "plt.plot(epochs, history.history['val_loss'])\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Fehler')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4aea4a",
   "metadata": {},
   "source": [
    "### Vorhersage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f15a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(fan_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e17284",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae440480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Konfusionsmatrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Wahre Klasse')\n",
    "    plt.xlabel('Vorhergesagte Klasse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a5b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = sklearn.metrics.confusion_matrix(fan_labels_test.argmax(axis=1), predict.round().argmax(axis=1))\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(numClasses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a509dc",
   "metadata": {},
   "source": [
    "### Konvertierung in TFLite-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e9fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantisierung und Optimierung für Microcontroller\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimazations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "TFLITE_MODEL_FILENAME = \"../model/predMaintenance.tflite\"\n",
    "open(TFLITE_MODEL_FILENAME, \"wb\").write(tflite_model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1d86d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embeddedml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
